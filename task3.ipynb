{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "source": [
    "# first lets run clean_text on the 'content' column\n",
    "from cleantext import clean\n",
    "def clean_text(s):\n",
    "    return clean(s,lower=True,                     # lowercase text\n",
    "        no_urls=True,                  # replace all URLs with a special token\n",
    "        no_emails=True,                # replace all email addresses with a special token\n",
    "        no_numbers=True,               # replace all numbers with a special token\n",
    "        replace_with_url=\"<URL>\",\n",
    "        replace_with_email=\"<EMAIL>\",\n",
    "        replace_with_number=\"<NUM>\",\n",
    "        lang=\"en\"                   \n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data in chunks and run in parallel\n",
    "from joblib import Parallel, delayed\n",
    "from os import cpu_count\n",
    "\n",
    "# run in parallel\n",
    "def run_parallel(df, n_jobs, func):\n",
    "    # call every element in the chunks in parallel\n",
    "    results = Parallel(n_jobs=n_jobs)(delayed(func)(element) for element in df)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the text\n",
    "def clean_column(df):\n",
    "    n_jobs = cpu_count()\n",
    "    results = run_parallel(df, n_jobs, clean_text)\n",
    "    # replace column with cleaned text\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "# tokenize the text. run in parallel\n",
    "def tokenize_column(df):\n",
    "    # run the function on the data\n",
    "    n_jobs = cpu_count()\n",
    "    results = run_parallel(df['content'], n_jobs, word_tokenize)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# removing generic stopwords\n",
    "def remove_stopwords(df):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # remove stopwords from the text\n",
    "    def r(s):\n",
    "        return [w for w in s if not w in stop_words]\n",
    "\n",
    "    # run the function on the df\n",
    "    n_jobs = cpu_count()\n",
    "    results = run_parallel(df, n_jobs, r)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading a small part of the data for testing\n",
    "df = pd.read_csv('D:/FakeNews_data/news.csv/news_cleaned_2018_02_13.csv', nrows=10000, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from os import remove\n",
    "# create a file to be used for storing the data\n",
    "def intialize_file(name):\n",
    "    # check if file exists\n",
    "    if path.exists(name):\n",
    "        # if the file exists, delete it\n",
    "        remove(name)\n",
    "    # create the file\n",
    "    with open(name, 'w') as f:\n",
    "        f.write('') # write an empty string to the file to create it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append data to csv file\n",
    "def append_to_file(name, data):\n",
    "    with open(name, 'a') as f:\n",
    "        # write the data to the file\n",
    "        f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a file to store the data\n",
    "tokenized_file = 'tokenized_temp.csv'\n",
    "intialize_file(tokenized_file)\n",
    "\n",
    "# append header to the file\n",
    "header = df.columns.values\n",
    "append_to_file(tokenized_file, ','.join(header))\n",
    "append_to_file(tokenized_file, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 chunks processed\n",
      "2 chunks processed\n",
      "3 chunks processed\n",
      "4 chunks processed\n",
      "5 chunks processed\n",
      "6 chunks processed\n",
      "7 chunks processed\n",
      "8 chunks processed\n",
      "9 chunks processed\n",
      "10 chunks processed\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('D:/FakeNews_data/news.csv/news_cleaned_2018_02_13.csv', chunksize=1000, index_col=0)\n",
    "\n",
    "count = 0\n",
    "for chunk in df:\n",
    "    # process data\n",
    "    chunk['content'] = clean_column(chunk['content'])\n",
    "    chunk['content'] = tokenize_column(chunk)\n",
    "    chunk['content'] = remove_stopwords(chunk['content'])\n",
    "    # append data to file\n",
    "    chunk.to_csv(tokenized_file, mode='a', header=False)\n",
    "\n",
    "    count += 1\n",
    "    print(count, 'chunks processed')\n",
    "    if count == 10:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from file\n",
    "tokenized_file = 'tokenized_temp.csv'\n",
    "df = pd.read_csv(tokenized_file)\n",
    "# load list from string\n",
    "from ast import literal_eval\n",
    "df['content'] = df['content'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# count the tokens\n",
    "def count(s):\n",
    "    return Counter(s)\n",
    "\n",
    "# count token frequency\n",
    "from collections import Counter\n",
    "def count_tokens(df):\n",
    "\n",
    "\n",
    "    # run the function on the df\n",
    "    n_jobs = cpu_count()\n",
    "    results = run_parallel(df, n_jobs, count)\n",
    "\n",
    "    # total token frequency\n",
    "    total = {}\n",
    "    for list in results:\n",
    "        for k,v in list.items():\n",
    "            if k in total:\n",
    "                total[k] += v\n",
    "            else:\n",
    "                total[k] = v\n",
    "\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_freq = count_tokens(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the tokens by frequency\n",
    "token_freq = sorted(token_freq.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a set of stopwords from the frequency list\n",
    "stop_words = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove top 10 tokens and add them to the stopword list\n",
    "for i in range(10):\n",
    "    stop_words.add(token_freq[i][0])\n",
    "\n",
    "token_freq = token_freq[10:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# find the 80% percentile\n",
    "# first finding the total number of tokens\n",
    "total = 0\n",
    "for token in token_freq:\n",
    "    total += token[1]\n",
    "# then finding the 80% percentile\n",
    "percentile = int(total * 0.8)\n",
    "# then finding the token that corresponds to the 80% percentile\n",
    "total = 0\n",
    "for token in token_freq:\n",
    "    total += token[1]\n",
    "    if total > percentile:\n",
    "        index = token_freq.index(token)\n",
    "        break\n",
    "# add all tokens after the 80% percentile to the stopword list\n",
    "for token in token_freq[index:]:\n",
    "    stop_words.add(token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109435"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove custom stopwords from the text\n",
    "def remove_costume_stopwords(df):\n",
    "    # remove stopwords from the text\n",
    "    def r(s):\n",
    "        return [w for w in s if not w in stop_words]\n",
    "\n",
    "    # run the function on the df\n",
    "    for i in range(len(df)):\n",
    "        df[i] = r(df[i])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musta\\AppData\\Local\\Temp\\ipykernel_26352\\1780968742.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[i] = r(df[i])\n"
     ]
    }
   ],
   "source": [
    "df['content'] = remove_costume_stopwords(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data\n",
    "df.to_csv('ready_data.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ready_data.csv')\n",
    "# load list from string\n",
    "from ast import literal_eval\n",
    "df['content'] = df['content'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train, test and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['content'], df['type'], test_size=0.2, random_state=42)\n",
    "X_test , X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bias          1.190083\n",
       "clickbait     1.027027\n",
       "conspiracy    1.001184\n",
       "fake          1.014581\n",
       "hate          1.025641\n",
       "junksci       0.709957\n",
       "political     1.006693\n",
       "reliable      1.006289\n",
       "rumor         1.674419\n",
       "satire        1.440000\n",
       "unknown       1.263158\n",
       "unreliable    0.970297\n",
       "Name: type, dtype: float64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()*8 / y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making labels binary\n",
    "y_train = y_train.apply(lambda x: 1 if x in ['fake', 'junksci', 'hate', 'clickbait',] else 0)\n",
    "y_test = y_test.apply(lambda x: 1 if x in ['fake', 'junksci', 'hate', 'clickbait',] else 0)\n",
    "y_val = y_val.apply(lambda x: 1 if x in ['fake', 'junksci', 'hate', 'clickbait',] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# function which pads pandas series\n",
    "def pad_series(s, max_len):\n",
    "    # truncate the series if it is longer than max_len\n",
    "    s = s.apply(lambda x: x[:max_len])\n",
    "\n",
    "    # pad the series\n",
    "    s = s.apply(lambda x: x + ['<pad>'] * (max_len - len(x)))\n",
    "\n",
    "    # convert the series to np array\n",
    "    s = np.array(s.tolist())\n",
    "    return s\n",
    "\n",
    "# pad the series and convert them to np arrays\n",
    "X_test = pad_series(X_test, 1000)\n",
    "X_train = pad_series(X_train, 1000)\n",
    "X_val = pad_series(X_val, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the strings to integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# fit the encoder on the training data\n",
    "le.fit(X_train.flatten())\n",
    "\n",
    "# transform the data\n",
    "X_train = le.transform(X_train.flatten()).reshape(X_train.shape)\n",
    "X_test = le.transform(X_test.flatten()).reshape(X_test.shape)\n",
    "X_val = le.transform(X_val.flatten()).reshape(X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.53075\n",
       "1    0.46925\n",
       "Name: type, dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ratio of fake news in the data\n",
    "y_train.value_counts() / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.541"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a baseline model\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create a dummy classifier\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "# fit the classifier\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the labels\n",
    "y_pred = dummy_clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.619"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making a baseline model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create a dummy classifier\n",
    "dummy_clf = LogisticRegression(max_iter=10000)\n",
    "# fit the classifier\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the labels\n",
    "y_pred = dummy_clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.649"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# create a dummy classifier\n",
    "dummy_clf = MLPClassifier(max_iter=10000, hidden_layer_sizes=(1000,200,))\n",
    "# fit the classifier\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "# predict the labels\n",
    "y_pred = dummy_clf.predict(X_test)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a vocab file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a vocabulary\n",
    "vocab = {}\n",
    "for token in token_freq:\n",
    "    if token[0] not in stop_words:\n",
    "        vocab[token[0]] = len(vocab)\n",
    "# save the vocabulary\n",
    "import pickle\n",
    "with open('vocab.pickle', 'wb') as f:\n",
    "    pickle.dump(vocab, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(': 0,\n",
       " \"n't\": 1,\n",
       " '?': 2,\n",
       " 'one': 3,\n",
       " 'people': 4,\n",
       " '!': 5,\n",
       " 'trump': 6,\n",
       " 'would': 7,\n",
       " 'us': 8,\n",
       " 'new': 9,\n",
       " 'said': 10,\n",
       " 'government': 11,\n",
       " 'president': 12,\n",
       " 'time': 13,\n",
       " 'also': 14,\n",
       " \"'\": 15,\n",
       " 'like': 16,\n",
       " 'obama': 17,\n",
       " 'world': 18,\n",
       " ';': 19,\n",
       " 'even': 20,\n",
       " 'many': 21,\n",
       " 'could': 22,\n",
       " 'years': 23,\n",
       " '-': 24,\n",
       " 'may': 25,\n",
       " 'first': 26,\n",
       " 'two': 27,\n",
       " '%': 28,\n",
       " '$': 29,\n",
       " 'state': 30,\n",
       " 'states': 31,\n",
       " 'american': 32,\n",
       " 'blockchain': 33,\n",
       " 'america': 34,\n",
       " 'get': 35,\n",
       " 'u.s.': 36,\n",
       " 'way': 37,\n",
       " 'year': 38,\n",
       " 'url': 39,\n",
       " 'right': 40,\n",
       " 'make': 41,\n",
       " 'know': 42,\n",
       " 'next': 43,\n",
       " 'united': 44,\n",
       " 'think': 45,\n",
       " '&': 46,\n",
       " 'see': 47,\n",
       " 'free': 48,\n",
       " 'much': 49,\n",
       " 'well': 50,\n",
       " 'life': 51,\n",
       " 'last': 52,\n",
       " 'country': 53,\n",
       " 'news': 54,\n",
       " 'fact': 55,\n",
       " 'back': 56,\n",
       " 'day': 57,\n",
       " 'take': 58,\n",
       " 'political': 59,\n",
       " 'bitcoin': 60,\n",
       " 'every': 61,\n",
       " 'war': 62,\n",
       " 'since': 63,\n",
       " 'need': 64,\n",
       " 'power': 65,\n",
       " \"'re\": 66,\n",
       " 'public': 67,\n",
       " 'good': 68,\n",
       " 'media': 69,\n",
       " 'law': 70,\n",
       " 'national': 71,\n",
       " 'story': 72,\n",
       " 'today': 73,\n",
       " 'going': 74,\n",
       " 'made': 75,\n",
       " 'another': 76,\n",
       " 'want': 77,\n",
       " 'house': 78,\n",
       " 'use': 79,\n",
       " 'according': 80,\n",
       " 'never': 81,\n",
       " 'god': 82,\n",
       " 'still': 83,\n",
       " 'money': 84,\n",
       " 'must': 85,\n",
       " 'work': 86,\n",
       " 'say': 87,\n",
       " 'federal': 88,\n",
       " 'stocks': 89,\n",
       " 'great': 90,\n",
       " 'around': 91,\n",
       " 'things': 92,\n",
       " 'go': 93,\n",
       " 'come': 94,\n",
       " 'source': 95,\n",
       " 'market': 96,\n",
       " 'long': 97,\n",
       " 'party': 98,\n",
       " 'without': 99,\n",
       " 'end': 100,\n",
       " 'americans': 101,\n",
       " 'policy': 102,\n",
       " 'headline': 103,\n",
       " 'system': 104,\n",
       " 'used': 105,\n",
       " 'clinton': 106,\n",
       " 'part': 107,\n",
       " 'million': 108,\n",
       " 'administration': 109,\n",
       " 'security': 110,\n",
       " 'searches': 111,\n",
       " 'exceed': 112,\n",
       " 'tax': 113,\n",
       " 'white': 114,\n",
       " 'military': 115,\n",
       " 'health': 116,\n",
       " 'times': 117,\n",
       " ']': 118,\n",
       " 'human': 119,\n",
       " '[': 120,\n",
       " 'something': 121,\n",
       " 'however': 122,\n",
       " 'north': 123,\n",
       " 'believe': 124,\n",
       " 'information': 125,\n",
       " 'really': 126,\n",
       " 'high': 127,\n",
       " 'washington': 128,\n",
       " 'rights': 129,\n",
       " 'report': 130,\n",
       " 'global': 131,\n",
       " 'percent': 132,\n",
       " 'become': 133,\n",
       " 'children': 134,\n",
       " 'left': 135,\n",
       " 'history': 136,\n",
       " 'including': 137,\n",
       " 'change': 138,\n",
       " 'control': 139,\n",
       " 'bill': 140,\n",
       " 'help': 141,\n",
       " 'yet': 142,\n",
       " \"'ve\": 143,\n",
       " 'man': 144,\n",
       " 'place': 145,\n",
       " 'congress': 146,\n",
       " 'support': 147,\n",
       " 'nation': 148,\n",
       " 'might': 149,\n",
       " 'israel': 150,\n",
       " 'women': 151,\n",
       " 'let': 152,\n",
       " 'week': 153,\n",
       " 'little': 154,\n",
       " 'recent': 155,\n",
       " 'economic': 156,\n",
       " 'case': 157,\n",
       " 'others': 158,\n",
       " 'group': 159,\n",
       " 'real': 160,\n",
       " 'democrats': 161,\n",
       " 'called': 162,\n",
       " 'told': 163,\n",
       " 'family': 164,\n",
       " 'found': 165,\n",
       " 'press': 166,\n",
       " 'find': 167,\n",
       " 'far': 168,\n",
       " 'full': 169,\n",
       " 'three': 170,\n",
       " 'energy': 171,\n",
       " 'order': 172,\n",
       " 'nuclear': 173,\n",
       " 'better': 174,\n",
       " 'days': 175,\n",
       " 'number': 176,\n",
       " 'former': 177,\n",
       " 'already': 178,\n",
       " 'church': 179,\n",
       " 'ever': 180,\n",
       " 'put': 181,\n",
       " 'john': 182,\n",
       " 'look': 183,\n",
       " 'actually': 184,\n",
       " 'police': 185,\n",
       " 'personal': 186,\n",
       " 'nothing': 187,\n",
       " 'big': 188,\n",
       " 'keep': 189,\n",
       " 'home': 190,\n",
       " 'freedom': 191,\n",
       " 'office': 192,\n",
       " 'court': 193,\n",
       " 'point': 194,\n",
       " 'best': 195,\n",
       " 'says': 196,\n",
       " 'fbi': 197,\n",
       " 'show': 198,\n",
       " 'read': 199,\n",
       " 'within': 200,\n",
       " 'video': 201,\n",
       " 'post': 202,\n",
       " 'past': 203,\n",
       " 'campaign': 204,\n",
       " 'always': 205,\n",
       " '/': 206,\n",
       " 'result': 207,\n",
       " 'general': 208,\n",
       " 'less': 209,\n",
       " 'january': 210,\n",
       " 'water': 211,\n",
       " 'away': 212,\n",
       " 'canada': 213,\n",
       " 'department': 214,\n",
       " 'black': 215,\n",
       " 'act': 216,\n",
       " 'article': 217,\n",
       " 'means': 218,\n",
       " \"'m\": 219,\n",
       " 'enough': 220,\n",
       " 'city': 221,\n",
       " 'countries': 222,\n",
       " 'social': 223,\n",
       " 'china': 224,\n",
       " 'thing': 225,\n",
       " 'love': 226,\n",
       " 'research': 227,\n",
       " 'donald': 228,\n",
       " 'major': 229,\n",
       " 'school': 230,\n",
       " 'among': 231,\n",
       " 'give': 232,\n",
       " 'election': 233,\n",
       " 'least': 234,\n",
       " 'course': 235,\n",
       " 'business': 236,\n",
       " 'truth': 237,\n",
       " 'important': 238,\n",
       " 'foreign': 239,\n",
       " 'different': 240,\n",
       " 'given': 241,\n",
       " 'society': 242,\n",
       " 'website': 243,\n",
       " 'add': 244,\n",
       " 'known': 245,\n",
       " 'book': 246,\n",
       " 'future': 247,\n",
       " 'making': 248,\n",
       " 'often': 249,\n",
       " 'though': 250,\n",
       " 'russia': 251,\n",
       " 'justice': 252,\n",
       " 'international': 253,\n",
       " 'hillary': 254,\n",
       " 'person': 255,\n",
       " 'members': 256,\n",
       " 'whether': 257,\n",
       " 'republican': 258,\n",
       " 'live': 259,\n",
       " 'korea': 260,\n",
       " 'oil': 261,\n",
       " \"'ll\": 262,\n",
       " 'earth': 263,\n",
       " 'men': 264,\n",
       " 'violence': 265,\n",
       " 'financial': 266,\n",
       " 'ca': 267,\n",
       " 'set': 268,\n",
       " 'true': 269,\n",
       " 'economy': 270,\n",
       " 'coming': 271,\n",
       " 'attacks': 272,\n",
       " 'deal': 273,\n",
       " 'food': 274,\n",
       " 'old': 275,\n",
       " 'likely': 276,\n",
       " 'billion': 277,\n",
       " 'second': 278,\n",
       " 'lives': 279,\n",
       " 'current': 280,\n",
       " 'readers': 281,\n",
       " 'question': 282,\n",
       " 'iran': 283,\n",
       " '*': 284,\n",
       " 'care': 285,\n",
       " 'nations': 286,\n",
       " 'republicans': 287,\n",
       " 'ago': 288,\n",
       " 'senate': 289,\n",
       " 'matter': 290,\n",
       " 'community': 291,\n",
       " 'across': 292,\n",
       " 'took': 293,\n",
       " 'words': 294,\n",
       " 'everything': 295,\n",
       " 'several': 296,\n",
       " 'plan': 297,\n",
       " 'seen': 298,\n",
       " 'program': 299,\n",
       " 'instead': 300,\n",
       " 'using': 301,\n",
       " 'able': 302,\n",
       " 'comes': 303,\n",
       " 'company': 304,\n",
       " 'attack': 305,\n",
       " 'got': 306,\n",
       " 'based': 307,\n",
       " 'death': 308,\n",
       " 'continue': 309,\n",
       " 'rather': 310,\n",
       " 'problem': 311,\n",
       " 'process': 312,\n",
       " '#': 313,\n",
       " 'data': 314,\n",
       " 'muslim': 315,\n",
       " 'came': 316,\n",
       " 'stop': 317,\n",
       " 'done': 318,\n",
       " 'call': 319,\n",
       " 'top': 320,\n",
       " 'example': 321,\n",
       " 'follow': 322,\n",
       " 'open': 323,\n",
       " 'possible': 324,\n",
       " 'following': 325,\n",
       " 'evidence': 326,\n",
       " 'please': 327,\n",
       " 'months': 328,\n",
       " 'gold': 329,\n",
       " 'issue': 330,\n",
       " 'anything': 331,\n",
       " 'citizens': 332,\n",
       " 'along': 333,\n",
       " 'york': 334,\n",
       " 'force': 335,\n",
       " 'clear': 336,\n",
       " 'university': 337,\n",
       " 'california': 338,\n",
       " 'almost': 339,\n",
       " 'simply': 340,\n",
       " 'lot': 341,\n",
       " 'reason': 342,\n",
       " 'study': 343,\n",
       " 'working': 344,\n",
       " 'upon': 345,\n",
       " 'south': 346,\n",
       " 'reported': 347,\n",
       " 'conservative': 348,\n",
       " 'pay': 349,\n",
       " 'anyone': 350,\n",
       " 'barack': 351,\n",
       " 'seems': 352,\n",
       " 'watch': 353,\n",
       " 'local': 354,\n",
       " 'four': 355,\n",
       " 'name': 356,\n",
       " 'dr.': 357,\n",
       " 'level': 358,\n",
       " 'democratic': 359,\n",
       " 'feel': 360,\n",
       " 'taking': 361,\n",
       " 'private': 362,\n",
       " 'vote': 363,\n",
       " 'sure': 364,\n",
       " 'move': 365,\n",
       " 'mind': 366,\n",
       " 'cents': 367,\n",
       " 'per': 368,\n",
       " 'christian': 369,\n",
       " 'officials': 370,\n",
       " 'illegal': 371,\n",
       " 'small': 372,\n",
       " 'un': 373,\n",
       " 'later': 374,\n",
       " 'higher': 375,\n",
       " 'constitution': 376,\n",
       " 'hard': 377,\n",
       " 'common': 378,\n",
       " 'december': 379,\n",
       " 'jesus': 380,\n",
       " 'immigration': 381,\n",
       " 'action': 382,\n",
       " 'everyone': 383,\n",
       " 'someone': 384,\n",
       " 'start': 385,\n",
       " 'large': 386,\n",
       " 'living': 387,\n",
       " 'natural': 388,\n",
       " 'leaders': 389,\n",
       " 'bad': 390,\n",
       " 'middle': 391,\n",
       " 'debt': 392,\n",
       " 'articles': 393,\n",
       " 'price': 394,\n",
       " 'rate': 395,\n",
       " 'makes': 396,\n",
       " 'body': 397,\n",
       " 'issues': 398,\n",
       " 'due': 399,\n",
       " 'groups': 400,\n",
       " 'recently': 401,\n",
       " 'thought': 402,\n",
       " 'legal': 403,\n",
       " 'special': 404,\n",
       " 'despite': 405,\n",
       " 'getting': 406,\n",
       " 'reports': 407,\n",
       " 'especially': 408,\n",
       " 'speech': 409,\n",
       " 'companies': 410,\n",
       " 'religious': 411,\n",
       " 'reality': 412,\n",
       " 'taken': 413,\n",
       " 'understand': 414,\n",
       " 'avoid': 415,\n",
       " 'idea': 416,\n",
       " 'november': 417,\n",
       " 'saying': 418,\n",
       " 'islamic': 419,\n",
       " 'investigation': 420,\n",
       " 'subscribe': 421,\n",
       " 'behind': 422,\n",
       " 'education': 423,\n",
       " 'email': 424,\n",
       " 'committee': 425,\n",
       " 'face': 426,\n",
       " 'run': 427,\n",
       " 'either': 428,\n",
       " 'statement': 429,\n",
       " 'early': 430,\n",
       " 'needs': 431,\n",
       " 'experience': 432,\n",
       " 'interest': 433,\n",
       " 'entire': 434,\n",
       " 'provide': 435,\n",
       " 'russian': 436,\n",
       " 'increase': 437,\n",
       " 'created': 438,\n",
       " 'longer': 439,\n",
       " '@': 440,\n",
       " 'together': 441,\n",
       " 'laws': 442,\n",
       " 'asked': 443,\n",
       " 'industry': 444,\n",
       " 'whole': 445,\n",
       " 'bank': 446,\n",
       " 'young': 447,\n",
       " 'science': 448,\n",
       " 'east': 449,\n",
       " 'center': 450,\n",
       " 'sense': 451,\n",
       " 'trying': 452,\n",
       " 'side': 453,\n",
       " 'threats': 454,\n",
       " 'went': 455,\n",
       " 'cause': 456,\n",
       " 'risk': 457,\n",
       " 'tell': 458,\n",
       " 'land': 459,\n",
       " 'policies': 460,\n",
       " 'peace': 461,\n",
       " 'trade': 462,\n",
       " 'kind': 463,\n",
       " 'five': 464,\n",
       " 'mr.': 465,\n",
       " 'director': 466,\n",
       " 'liberal': 467,\n",
       " 'climate': 468,\n",
       " 'jobs': 469,\n",
       " 'light': 470,\n",
       " 'head': 471,\n",
       " 'daily': 472,\n",
       " 'view': 473,\n",
       " 'intelligence': 474,\n",
       " 'team': 475,\n",
       " 'total': 476,\n",
       " 'job': 477,\n",
       " 'organization': 478,\n",
       " 'month': 479,\n",
       " 'wrote': 480,\n",
       " 'leader': 481,\n",
       " 'growth': 482,\n",
       " 'lost': 483,\n",
       " 'bring': 484,\n",
       " 'area': 485,\n",
       " 'nearly': 486,\n",
       " 'wrong': 487,\n",
       " 'close': 488,\n",
       " 'west': 489,\n",
       " 'hand': 490,\n",
       " 'word': 491,\n",
       " 'perhaps': 492,\n",
       " 'wall': 493,\n",
       " 'form': 494,\n",
       " 'decision': 495,\n",
       " 'author': 496,\n",
       " 'meeting': 497,\n",
       " 'continued': 498,\n",
       " 'weapons': 499,\n",
       " 'hope': 500,\n",
       " 'gun': 501,\n",
       " 'medical': 502,\n",
       " 'lead': 503,\n",
       " '--': 504,\n",
       " 'turn': 505,\n",
       " 'individual': 506,\n",
       " 'politics': 507,\n",
       " 'defense': 508,\n",
       " 'david': 509,\n",
       " 'central': 510,\n",
       " 'service': 511,\n",
       " 'technology': 512,\n",
       " 'crisis': 513,\n",
       " 'hear': 514,\n",
       " 'looking': 515,\n",
       " 'short': 516,\n",
       " 'create': 517,\n",
       " 'list': 518,\n",
       " 'foundation': 519,\n",
       " 'mean': 520,\n",
       " 'ban': 521,\n",
       " 'march': 522,\n",
       " 'line': 523,\n",
       " 'population': 524,\n",
       " 'member': 525,\n",
       " 'official': 526,\n",
       " 'agency': 527,\n",
       " 'include': 528,\n",
       " 'comment': 529,\n",
       " 'forces': 530,\n",
       " 'wo': 531,\n",
       " 'fire': 532,\n",
       " 'began': 533,\n",
       " 'remove': 534,\n",
       " 'reserve': 535,\n",
       " 'appeared': 536,\n",
       " 'street': 537,\n",
       " 'event': 538,\n",
       " 'strong': 539,\n",
       " 'prices': 540,\n",
       " 'europe': 541,\n",
       " 'secretary': 542,\n",
       " 'spending': 543,\n",
       " 'shall': 544,\n",
       " 'child': 545,\n",
       " 'millions': 546,\n",
       " 'jim': 547,\n",
       " 'average': 548,\n",
       " 'protect': 549,\n",
       " 'paul': 550,\n",
       " 'dollars': 551,\n",
       " 'night': 552,\n",
       " 'events': 553,\n",
       " 'available': 554,\n",
       " 'majority': 555,\n",
       " 'heart': 556,\n",
       " 'ways': 557,\n",
       " 'published': 558,\n",
       " 'else': 559,\n",
       " 'threat': 560,\n",
       " 'share': 561,\n",
       " 'students': 562,\n",
       " 'potential': 563,\n",
       " 'term': 564,\n",
       " 'deep': 565,\n",
       " 'union': 566,\n",
       " 'council': 567,\n",
       " 'soon': 568,\n",
       " 'democrat': 569,\n",
       " 'presidential': 570,\n",
       " 'air': 571,\n",
       " 'claims': 572,\n",
       " 'racism': 573,\n",
       " 'movement': 574,\n",
       " 'friends': 575,\n",
       " 'civil': 576,\n",
       " 'key': 577,\n",
       " 'christians': 578,\n",
       " 'quite': 579,\n",
       " 'although': 580,\n",
       " 'fear': 581,\n",
       " 'internet': 582,\n",
       " 'markets': 583,\n",
       " 'agenda': 584,\n",
       " 'removed': 585,\n",
       " 'via': 586,\n",
       " 'outside': 587,\n",
       " 'minister': 588,\n",
       " 'allow': 589,\n",
       " 'shows': 590,\n",
       " 'finally': 591,\n",
       " '...': 592,\n",
       " 'islam': 593,\n",
       " 'age': 594,\n",
       " 'criminal': 595,\n",
       " 'questions': 596,\n",
       " 'became': 597,\n",
       " 'goes': 598,\n",
       " 'thousands': 599,\n",
       " 'problems': 600,\n",
       " \"'d\": 601,\n",
       " 'added': 602,\n",
       " 'released': 603,\n",
       " 'actions': 604,\n",
       " 'single': 605,\n",
       " 'half': 606,\n",
       " 'authority': 607,\n",
       " 'wants': 608,\n",
       " 'levels': 609,\n",
       " 'try': 610,\n",
       " 'certain': 611,\n",
       " 'low': 612,\n",
       " 'rule': 613,\n",
       " 'currently': 614,\n",
       " 'rest': 615,\n",
       " 'services': 616,\n",
       " 'written': 617,\n",
       " 'probably': 618,\n",
       " 'claim': 619,\n",
       " 'whose': 620,\n",
       " 'indeed': 621,\n",
       " 'capital': 622,\n",
       " 'rates': 623,\n",
       " 'talk': 624,\n",
       " 'false': 625,\n",
       " 'latest': 626,\n",
       " 'army': 627,\n",
       " 'learn': 628,\n",
       " 'remember': 629,\n",
       " 'buy': 630,\n",
       " 'happen': 631,\n",
       " 'stand': 632,\n",
       " 'october': 633,\n",
       " 'attention': 634,\n",
       " 'growing': 635,\n",
       " 'owned': 636,\n",
       " 'christmas': 637,\n",
       " 'consider': 638,\n",
       " 'users': 639,\n",
       " 'record': 640,\n",
       " 'response': 641,\n",
       " 'terrorist': 642,\n",
       " 'development': 643,\n",
       " 'seem': 644,\n",
       " 'religion': 645,\n",
       " 'contain': 646,\n",
       " 'happened': 647,\n",
       " 'message': 648,\n",
       " 'held': 649,\n",
       " 'james': 650,\n",
       " 'led': 651,\n",
       " 'check': 652,\n",
       " 'rise': 653,\n",
       " 'front': 654,\n",
       " 'throughout': 655,\n",
       " 'cost': 656,\n",
       " 'lower': 657,\n",
       " 'present': 658,\n",
       " 'started': 659,\n",
       " 'critical': 660,\n",
       " 'role': 661,\n",
       " 'liberty': 662,\n",
       " 'involved': 663,\n",
       " 'hold': 664,\n",
       " 'various': 665,\n",
       " 'class': 666,\n",
       " 'position': 667,\n",
       " 'answer': 668,\n",
       " 'jerusalem': 669,\n",
       " 'executive': 670,\n",
       " 'car': 671,\n",
       " 'near': 672,\n",
       " 'late': 673,\n",
       " 'born': 674,\n",
       " 'secret': 675,\n",
       " 'politicians': 676,\n",
       " 'abortion': 677,\n",
       " 'faith': 678,\n",
       " 'european': 679,\n",
       " 'father': 680,\n",
       " 'culture': 681,\n",
       " 'taxes': 682,\n",
       " 'killed': 683,\n",
       " 'allowed': 684,\n",
       " 'banned': 685,\n",
       " 'alone': 686,\n",
       " 'dollar': 687,\n",
       " 'morning': 688,\n",
       " 'worked': 689,\n",
       " 'george': 690,\n",
       " 'candidate': 691,\n",
       " 'value': 692,\n",
       " 'toward': 693,\n",
       " 'woman': 694,\n",
       " 'demand': 695,\n",
       " 'massive': 696,\n",
       " 'income': 697,\n",
       " 'period': 698,\n",
       " 'impact': 699,\n",
       " 'heard': 700,\n",
       " 'situation': 701,\n",
       " 'attorney': 702,\n",
       " 'fight': 703,\n",
       " 'property': 704,\n",
       " 'ask': 705,\n",
       " 'parents': 706,\n",
       " 'yes': 707,\n",
       " 'western': 708,\n",
       " 'crime': 709,\n",
       " 'six': 710,\n",
       " 'hours': 711,\n",
       " 'saw': 712,\n",
       " 'needed': 713,\n",
       " 'supreme': 714,\n",
       " 'access': 715,\n",
       " 'cancer': 716,\n",
       " 'wanted': 717,\n",
       " 'regime': 718,\n",
       " 'image': 719,\n",
       " 'mueller': 720,\n",
       " 'banks': 721,\n",
       " 'efforts': 722,\n",
       " 'beyond': 723,\n",
       " 'workers': 724,\n",
       " 'weeks': 725,\n",
       " 'institute': 726,\n",
       " 'decades': 727,\n",
       " 'spirit': 728,\n",
       " 'leadership': 729,\n",
       " 'project': 730,\n",
       " 'brought': 731,\n",
       " 'page': 732,\n",
       " 'sign': 733,\n",
       " 'thus': 734,\n",
       " 'similar': 735,\n",
       " 'individuals': 736,\n",
       " 'click': 737,\n",
       " 'series': 738,\n",
       " 'worse': 739,\n",
       " 'stock': 740,\n",
       " 'facebook': 741,\n",
       " 'plans': 742,\n",
       " 'blood': 743,\n",
       " 'stated': 744,\n",
       " 'serious': 745,\n",
       " 'sent': 746,\n",
       " 'robert': 747,\n",
       " 'nature': 748,\n",
       " 'received': 749,\n",
       " 'announced': 750,\n",
       " 'ground': 751,\n",
       " 'jan': 752,\n",
       " 'running': 753,\n",
       " 'bush': 754,\n",
       " 'chief': 755,\n",
       " 'reform': 756,\n",
       " 'talking': 757,\n",
       " 'failed': 758,\n",
       " 'hands': 759,\n",
       " 'user': 760,\n",
       " 'ability': 761,\n",
       " 'space': 762,\n",
       " 'sexual': 763,\n",
       " 'moment': 764,\n",
       " 'legislation': 765,\n",
       " 'amount': 766,\n",
       " 'powerful': 767,\n",
       " 'remain': 768,\n",
       " 'passed': 769,\n",
       " 'release': 770,\n",
       " 'families': 771,\n",
       " 'christ': 772,\n",
       " 'dangerous': 773,\n",
       " 'advertising': 774,\n",
       " 'fall': 775,\n",
       " 'effort': 776,\n",
       " 'forward': 777,\n",
       " 'radio': 778,\n",
       " 'race': 779,\n",
       " 'begin': 780,\n",
       " 'expected': 781,\n",
       " 'safety': 782,\n",
       " 'border': 783,\n",
       " 'michael': 784,\n",
       " 'hit': 785,\n",
       " 'continues': 786,\n",
       " 'credit': 787,\n",
       " 'cut': 788,\n",
       " 'third': 789,\n",
       " 'review': 790,\n",
       " 'results': 791,\n",
       " 'original': 792,\n",
       " 'september': 793,\n",
       " 'mass': 794,\n",
       " 'ones': 795,\n",
       " 'leave': 796,\n",
       " 'gas': 797,\n",
       " 'maybe': 798,\n",
       " 'address': 799,\n",
       " 'king': 800,\n",
       " 'dead': 801,\n",
       " 'schools': 802,\n",
       " 'pass': 803,\n",
       " 'network': 804,\n",
       " 'return': 805,\n",
       " 'numbers': 806,\n",
       " 'building': 807,\n",
       " 'inside': 808,\n",
       " 'programs': 809,\n",
       " 'lack': 810,\n",
       " 'college': 811,\n",
       " 'twitter': 812,\n",
       " 'certainly': 813,\n",
       " 'sources': 814,\n",
       " 'tuesday': 815,\n",
       " 'mainstream': 816,\n",
       " 'lisa': 817,\n",
       " 'elected': 818,\n",
       " 'drug': 819,\n",
       " 'friday': 820,\n",
       " 'leading': 821,\n",
       " 'win': 822,\n",
       " 'relationship': 823,\n",
       " 'voters': 824,\n",
       " 'british': 825,\n",
       " 'step': 826,\n",
       " 'gave': 827,\n",
       " 'cases': 828,\n",
       " 'completely': 829,\n",
       " 'modern': 830,\n",
       " 'century': 831,\n",
       " 'cities': 832,\n",
       " 'stories': 833,\n",
       " 'amendment': 834,\n",
       " 'play': 835,\n",
       " 'budget': 836,\n",
       " 'game': 837,\n",
       " 'appears': 838,\n",
       " 'planned': 839,\n",
       " 'beginning': 840,\n",
       " 'poor': 841,\n",
       " 'interview': 842,\n",
       " 'mark': 843,\n",
       " 'syria': 844,\n",
       " 'earlier': 845,\n",
       " 'increased': 846,\n",
       " 'instructions': 847,\n",
       " 'privately': 848,\n",
       " 'dec': 849,\n",
       " 'works': 850,\n",
       " 'opportunity': 851,\n",
       " 'speak': 852,\n",
       " 'thinking': 853,\n",
       " 'anti-semitism': 854,\n",
       " 'birth': 855,\n",
       " 'significant': 856,\n",
       " 'worth': 857,\n",
       " 'exactly': 858,\n",
       " 'considered': 859,\n",
       " 'terms': 860,\n",
       " 'huge': 861,\n",
       " 'benefits': 862,\n",
       " 'effect': 863,\n",
       " 'iraq': 864,\n",
       " 'muslims': 865,\n",
       " 'areas': 866,\n",
       " 'therefore': 867,\n",
       " 'regarding': 868,\n",
       " 'evil': 869,\n",
       " 'paid': 870,\n",
       " 'thursday': 871,\n",
       " 'funding': 872,\n",
       " 'turned': 873,\n",
       " 'clearly': 874,\n",
       " 'fed': 875,\n",
       " 'largest': 876,\n",
       " 'abusive': 877,\n",
       " 'oct': 878,\n",
       " 'stay': 879,\n",
       " 'immigrants': 880,\n",
       " 'changes': 881,\n",
       " 'forced': 882,\n",
       " 'board': 883,\n",
       " 'whatever': 884,\n",
       " 'congressional': 885,\n",
       " 'june': 886,\n",
       " 'knew': 887,\n",
       " 'room': 888,\n",
       " 'systems': 889,\n",
       " 'wealth': 890,\n",
       " 'popular': 891,\n",
       " 'annual': 892,\n",
       " 'simple': 893,\n",
       " 'gop': 894,\n",
       " 'studies': 895,\n",
       " 'caused': 896,\n",
       " 'jewish': 897,\n",
       " 'organizations': 898,\n",
       " 'documents': 899,\n",
       " 'related': 900,\n",
       " 'establishment': 901,\n",
       " 'safe': 902,\n",
       " 'points': 903,\n",
       " 'interests': 904,\n",
       " 'adhere': 905,\n",
       " 'commenting': 906,\n",
       " 'greater': 907,\n",
       " 'necessary': 908,\n",
       " 'monday': 909,\n",
       " 'online': 910,\n",
       " 'difficult': 911,\n",
       " 'bit': 912,\n",
       " 'armed': 913,\n",
       " 'knows': 914,\n",
       " 'costs': 915,\n",
       " 'pressure': 916,\n",
       " 'note': 917,\n",
       " 'agreement': 918,\n",
       " 'takes': 919,\n",
       " 'choice': 920,\n",
       " 'products': 921,\n",
       " 'tv': 922,\n",
       " 'al': 923,\n",
       " 'influence': 924,\n",
       " 'obamacare': 925,\n",
       " 'warning': 926,\n",
       " 'wednesday': 927,\n",
       " 'focus': 928,\n",
       " 'responsible': 929,\n",
       " 'theory': 930,\n",
       " 'noted': 931,\n",
       " 'green': 932,\n",
       " 'investment': 933,\n",
       " 'quickly': 934,\n",
       " 'governments': 935,\n",
       " 'included': 936,\n",
       " 'resources': 937,\n",
       " 'prevent': 938,\n",
       " 'fox': 939,\n",
       " 'spam': 940,\n",
       " 'visit': 941,\n",
       " 'association': 942,\n",
       " 'rules': 943,\n",
       " 'registering': 944,\n",
       " 'purpose': 945,\n",
       " 'texas': 946,\n",
       " 'strategy': 947,\n",
       " 'main': 948,\n",
       " 'region': 949,\n",
       " 'spent': 950,\n",
       " 'values': 951,\n",
       " 'truly': 952,\n",
       " 'nov': 953,\n",
       " 'terrorism': 954,\n",
       " 'subject': 955,\n",
       " 'saudi': 956,\n",
       " 'trust': 957,\n",
       " 'brain': 958,\n",
       " 'offer': 959,\n",
       " 'vulgarity': 960,\n",
       " 'corporate': 961,\n",
       " 'type': 962,\n",
       " 'goal': 963,\n",
       " 'jews': 964,\n",
       " 'fund': 965,\n",
       " 'insurance': 966,\n",
       " 'expect': 967,\n",
       " 'calling': 968,\n",
       " 'independent': 969,\n",
       " 'constitutional': 970,\n",
       " 'revealed': 971,\n",
       " 'currency': 972,\n",
       " 'agencies': 973,\n",
       " 'citizen': 974,\n",
       " 'time.comments': 975,\n",
       " 'ban.': 976,\n",
       " 'particularly': 977,\n",
       " 'facts': 978,\n",
       " 'democracy': 979,\n",
       " 'district': 980,\n",
       " 'reasons': 981,\n",
       " 'debate': 982,\n",
       " 'enforcement': 983,\n",
       " 'hundreds': 984,\n",
       " 'effects': 985,\n",
       " 'inflation': 986,\n",
       " 'served': 987,\n",
       " 'solar': 988,\n",
       " 'status': 989,\n",
       " 'decided': 990,\n",
       " 'lies': 991,\n",
       " 'easy': 992,\n",
       " 'sometimes': 993,\n",
       " 'conference': 994,\n",
       " 'conservatives': 995,\n",
       " 'staff': 996,\n",
       " 'attempt': 997,\n",
       " 'physical': 998,\n",
       " 'baptist': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the vocabulary\n",
    "import pickle\n",
    "with open('vocab.pickle', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "\n",
    "vocab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fakeNewsProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37ef1759c6e89e8d70b9e29662a61b8d9623ea595ee6c595f52ac5c809a12b57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
