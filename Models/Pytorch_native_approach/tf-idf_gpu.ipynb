{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import IterableDataset\n",
    "from torch.utils.data import get_worker_info\n",
    "from torch.utils.data import RandomSampler\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iterator(csv_file='E:/ML/DS_fake_news/fake_news_cleaned.csv'):\n",
    "    data = pd.read_csv(csv_file, usecols=['content', 'type'], chunksize=2000)\n",
    "    label_map = {'bias': 0,\n",
    "                        'clickbait': 1,\n",
    "                        'conspiracy': 2,\n",
    "                        'fake': 3,\n",
    "                        'hate': 4,\n",
    "                        'junksci': 5,\n",
    "                        'political': 6,\n",
    "                        'reliable': 7,\n",
    "                        'rumor': 8,\n",
    "                        'satire': 9,\n",
    "                        'unreliable': 10}\n",
    "    for chunk in data:\n",
    "        # throw away rows with missing type\n",
    "        chunk = chunk.dropna(subset=['type'])\n",
    "        # drop rows with 'unknown' type\n",
    "        chunk = chunk[chunk['type'] != 'unknown']\n",
    "        chunk['type'] = chunk['type'].map(label_map)\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# loading vocabulary from pickle file\n",
    "vocab = pickle.load(open('E:/ML/DS_fake_news/vocab.pkl', 'rb'))\n",
    "#convert to dictionary\n",
    "vocab = {word: i for word, i in vocab}\n",
    "# remove words that appear less than 2000 times\n",
    "vocab = [word for word in vocab if vocab[word] > 1000]\n",
    "# replace value with index\n",
    "vocab = {word: i for i, word in enumerate(vocab)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "vectorizer = HashingVectorizer(n_features=2**16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_iterator()\n",
    "\n",
    "for chunk in data:\n",
    "    # transform the text to tf-idf\n",
    "    tfidf = vectorizer.transform(chunk['content'])\n",
    "    labels = chunk['type']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_data = tfidf\n",
    "y_data = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset using sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42, stratify=y_data)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to coo matrix\n",
    "X_train = X_train.tocoo()\n",
    "X_test = X_test.tocoo()\n",
    "X_val = X_val.tocoo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to torch tensors\n",
    "X_train = torch.sparse_coo_tensor(torch.LongTensor([X_train.row, X_train.col]), torch.FloatTensor(X_train.data), X_train.shape)\n",
    "X_test = torch.sparse_coo_tensor(torch.LongTensor([X_test.row, X_test.col]), torch.FloatTensor(X_test.data), X_test.shape)\n",
    "X_val = torch.sparse_coo_tensor(torch.LongTensor([X_val.row, X_val.col]), torch.FloatTensor(X_val.data), X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mNLLLoss()\n\u001b[0;32m     12\u001b[0m \u001b[39m# Forward pass, log  \u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m logps \u001b[39m=\u001b[39m model(X_train)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Calculate the loss with the logits and the labels\u001b[39;00m\n\u001b[0;32m     15\u001b[0m loss \u001b[39m=\u001b[39m criterion(logps, y_train)\n",
      "File \u001b[1;32md:\\Programmer\\anaconda_3\\envs\\fakeNewsProject\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Programmer\\anaconda_3\\envs\\fakeNewsProject\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[0;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[1;32md:\\Programmer\\anaconda_3\\envs\\fakeNewsProject\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Programmer\\anaconda_3\\envs\\fakeNewsProject\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "model = nn.Sequential(\n",
    "             nn.Linear(X_train.shape[1], 64),\n",
    "             nn.ReLU(),\n",
    "             nn.Linear(64, len(set(y_train))),\n",
    "             nn.LogSoftmax(dim=1))\n",
    "# Define the loss\n",
    "criterion = nn.NLLLoss()\n",
    "# Forward pass, log  \n",
    "logps = model(X_train)\n",
    "# Calculate the loss with the logits and the labels\n",
    "loss = criterion(logps, y_train)\n",
    "loss.backward()\n",
    "# Optimizers need parameters to optimize and a learning rate\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50..  Train loss: 7.141..  Test loss: 7.004..  Test accuracy: 0.430\n",
      "Epoch 2/50..  Train loss: 6.946..  Test loss: 6.800..  Test accuracy: 0.447\n",
      "Epoch 3/50..  Train loss: 6.739..  Test loss: 6.583..  Test accuracy: 0.442\n",
      "Epoch 4/50..  Train loss: 6.520..  Test loss: 6.354..  Test accuracy: 0.432\n",
      "Epoch 5/50..  Train loss: 6.288..  Test loss: 6.113..  Test accuracy: 0.421\n",
      "Epoch 6/50..  Train loss: 6.044..  Test loss: 5.861..  Test accuracy: 0.420\n",
      "Epoch 7/50..  Train loss: 5.789..  Test loss: 5.598..  Test accuracy: 0.434\n",
      "Epoch 8/50..  Train loss: 5.524..  Test loss: 5.327..  Test accuracy: 0.471\n",
      "Epoch 9/50..  Train loss: 5.250..  Test loss: 5.050..  Test accuracy: 0.497\n",
      "Epoch 10/50..  Train loss: 4.971..  Test loss: 4.771..  Test accuracy: 0.512\n",
      "Epoch 11/50..  Train loss: 4.689..  Test loss: 4.493..  Test accuracy: 0.526\n",
      "Epoch 12/50..  Train loss: 4.410..  Test loss: 4.221..  Test accuracy: 0.545\n",
      "Epoch 13/50..  Train loss: 4.137..  Test loss: 3.960..  Test accuracy: 0.547\n",
      "Epoch 14/50..  Train loss: 3.875..  Test loss: 3.713..  Test accuracy: 0.547\n",
      "Epoch 15/50..  Train loss: 3.628..  Test loss: 3.482..  Test accuracy: 0.545\n",
      "Epoch 16/50..  Train loss: 3.397..  Test loss: 3.268..  Test accuracy: 0.538\n",
      "Epoch 17/50..  Train loss: 3.182..  Test loss: 3.070..  Test accuracy: 0.540\n",
      "Epoch 18/50..  Train loss: 2.985..  Test loss: 2.889..  Test accuracy: 0.537\n",
      "Epoch 19/50..  Train loss: 2.803..  Test loss: 2.724..  Test accuracy: 0.544\n",
      "Epoch 20/50..  Train loss: 2.638..  Test loss: 2.575..  Test accuracy: 0.550\n",
      "Epoch 21/50..  Train loss: 2.488..  Test loss: 2.442..  Test accuracy: 0.554\n",
      "Epoch 22/50..  Train loss: 2.355..  Test loss: 2.326..  Test accuracy: 0.550\n",
      "Epoch 23/50..  Train loss: 2.237..  Test loss: 2.226..  Test accuracy: 0.561\n",
      "Epoch 24/50..  Train loss: 2.135..  Test loss: 2.140..  Test accuracy: 0.579\n",
      "Epoch 25/50..  Train loss: 2.047..  Test loss: 2.067..  Test accuracy: 0.588\n",
      "Epoch 26/50..  Train loss: 1.971..  Test loss: 2.007..  Test accuracy: 0.595\n",
      "Epoch 27/50..  Train loss: 1.907..  Test loss: 1.956..  Test accuracy: 0.605\n",
      "Epoch 28/50..  Train loss: 1.853..  Test loss: 1.914..  Test accuracy: 0.608\n",
      "Epoch 29/50..  Train loss: 1.806..  Test loss: 1.878..  Test accuracy: 0.610\n",
      "Epoch 30/50..  Train loss: 1.766..  Test loss: 1.847..  Test accuracy: 0.613\n",
      "Epoch 31/50..  Train loss: 1.729..  Test loss: 1.819..  Test accuracy: 0.615\n",
      "Epoch 32/50..  Train loss: 1.695..  Test loss: 1.793..  Test accuracy: 0.619\n",
      "Epoch 33/50..  Train loss: 1.663..  Test loss: 1.767..  Test accuracy: 0.619\n",
      "Epoch 34/50..  Train loss: 1.630..  Test loss: 1.741..  Test accuracy: 0.619\n",
      "Epoch 35/50..  Train loss: 1.598..  Test loss: 1.715..  Test accuracy: 0.618\n",
      "Epoch 36/50..  Train loss: 1.565..  Test loss: 1.689..  Test accuracy: 0.617\n",
      "Epoch 37/50..  Train loss: 1.531..  Test loss: 1.663..  Test accuracy: 0.618\n",
      "Epoch 38/50..  Train loss: 1.497..  Test loss: 1.637..  Test accuracy: 0.620\n",
      "Epoch 39/50..  Train loss: 1.464..  Test loss: 1.612..  Test accuracy: 0.620\n",
      "Epoch 40/50..  Train loss: 1.431..  Test loss: 1.589..  Test accuracy: 0.625\n",
      "Epoch 41/50..  Train loss: 1.400..  Test loss: 1.567..  Test accuracy: 0.629\n",
      "Epoch 42/50..  Train loss: 1.370..  Test loss: 1.548..  Test accuracy: 0.631\n",
      "Epoch 43/50..  Train loss: 1.342..  Test loss: 1.530..  Test accuracy: 0.640\n",
      "Epoch 44/50..  Train loss: 1.316..  Test loss: 1.513..  Test accuracy: 0.644\n",
      "Epoch 45/50..  Train loss: 1.291..  Test loss: 1.497..  Test accuracy: 0.642\n",
      "Epoch 46/50..  Train loss: 1.267..  Test loss: 1.481..  Test accuracy: 0.643\n",
      "Epoch 47/50..  Train loss: 1.242..  Test loss: 1.465..  Test accuracy: 0.643\n",
      "Epoch 48/50..  Train loss: 1.218..  Test loss: 1.448..  Test accuracy: 0.646\n",
      "Epoch 49/50..  Train loss: 1.193..  Test loss: 1.430..  Test accuracy: 0.646\n",
      "Epoch 50/50..  Train loss: 1.168..  Test loss: 1.413..  Test accuracy: 0.644\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for e in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model.forward(X_train)\n",
    "    loss = criterion(output, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        log_ps = model(X_test)\n",
    "        test_loss = criterion(log_ps, y_test)\n",
    "        ps = torch.exp(log_ps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        equals = top_class == y_test.view(*top_class.shape)\n",
    "        test_accuracy = torch.mean(equals.float())\n",
    "    \n",
    "    print(f\"Epoch {e+1}/{epochs}.. \",\n",
    "            f\"Train loss: {loss:.3f}.. \",\n",
    "            f\"Test loss: {test_loss:.3f}.. \",\n",
    "            f\"Test accuracy: {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the data to the next \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fakeNewsProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
